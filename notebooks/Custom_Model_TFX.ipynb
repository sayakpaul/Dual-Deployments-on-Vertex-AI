{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTVp-9PGYFIO"
   },
   "source": [
    "In this notebook, we will build two custom models - one for Endpoint deployment and the other one for mobile deployment. We will write a TFX pipeline to run their training and export. The entire pipeline will be orchestrated using [Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7gJqmqrsfqh"
   },
   "source": [
    "## References\n",
    "\n",
    "This notebook refers to the following resources and also reuses parts of the code from there: \n",
    "* [Simple TFX Pipeline for Vertex Pipelines](https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/gcp/vertex_pipelines_simple.ipynb)\n",
    "* [Vertex AI Training with TFX and Vertex Pipelines](https://www.tensorflow.org/tfx/tutorials/tfx/gcp/vertex_pipelines_vertex_training)\n",
    "* [Importing models to Vertex AI](https://cloud.google.com/vertex-ai/docs/general/import-model)\n",
    "* [Deploying a model using the Vertex AI API](https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api)\n",
    "* [MLOPs with Vertex AI](https://github.com/GoogleCloudPlatform/mlops-with-vertex-ai)\n",
    "* [Custom components TFX](https://www.tensorflow.org/tfx/tutorials/tfx/python_function_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D04aKMGWXjOu"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_niUhp_TY1G"
   },
   "outputs": [],
   "source": [
    "# Use the latest version of pip.\n",
    "%%capture\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade tfx==1.0.0 kfp==1.6.1\n",
    "!pip install -q --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVmgQ6w1oT_Z"
   },
   "source": [
    "### ***Please restart runtime before continuing.*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mstgsNHWoiXk"
   },
   "outputs": [],
   "source": [
    "!gcloud init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pl8ewjX3oXRx"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqVWpmywXngD"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wptXF0e-UXsT",
    "outputId": "1bb97d2e-f3f5-419f-e987-b2847a6adb8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.5.0\n",
      "TFX version: 1.0.0\n",
      "KFP version: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "from tfx import v1 as tfx\n",
    "print('TFX version: {}'.format(tfx.__version__))\n",
    "import kfp\n",
    "print('KFP version: {}'.format(kfp.__version__))\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFYHeepnXxpZ"
   },
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zPVyBrXrW-vu"
   },
   "outputs": [],
   "source": [
    "GOOGLE_CLOUD_PROJECT = 'fast-ai-exploration'    #@param {type:\"string\"}\n",
    "GOOGLE_CLOUD_REGION = 'us-central1'             #@param {type:\"string\"}\n",
    "GCS_BUCKET_NAME = 'vertex-tfx-mlops'            #@param {type:\"string\"}\n",
    "\n",
    "if not (GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_REGION and GCS_BUCKET_NAME):\n",
    "    from absl import logging\n",
    "    logging.error('Please set all required parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV-BZSvQq7YY"
   },
   "source": [
    "The location of the bucket must be a single region. Also, the bucket needs to be created in a region when [Vertex AI services are available](https://cloud.google.com/vertex-ai/docs/general/locations#available_regions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J65KHrt4X-Fu",
    "outputId": "085fe0e1-02fd-47e3-bc6e-ee24ad82b1b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_ROOT: gs://demo-experiments-gde-csp/pipeline_root/two-way-vertex-pipelines5\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_NAME = 'two-way-vertex-pipelines5'\n",
    "\n",
    "# Path to various pipeline artifact.\n",
    "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(\n",
    "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "# Paths for users' Python module.\n",
    "MODULE_ROOT = 'gs://{}/pipeline_module/{}'.format(\n",
    "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "# Paths for input data.\n",
    "DATA_ROOT = 'gs://flowers-public/tfrecords-jpeg-224x224'\n",
    "\n",
    "# This is the path where your model will be pushed for serving.\n",
    "SERVING_MODEL_DIR = 'gs://{}/serving_model/{}'.format(\n",
    "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three things you need for Firebase setup, and you can find a sufficient description for those in [Deploy and manage custom models with Firebase Admin SDK](https://firebase.google.com/docs/ml/manage-hosted-models) official document. \n",
    "\n",
    "1. You need to obtain credential file for your Firebase project\n",
    "  - On the [Settings](https://console.firebase.google.com/project/_/settings/serviceaccounts/adminsdk) page, create a service account and download the service account key file. Keep this file safe, since it grants administrator access to your project.\n",
    "  - Save the credential JSON file in a GCS bucket, and replace the `FIREBASE_CREDENTIAL_PATH` value with it.\n",
    "\n",
    "\n",
    "\n",
    "2. You need to create a GCS bucket where the model is going to be temporarily stored.\n",
    "  - On the Storage page, enable Cloud Storage. Take note of your bucket name.\n",
    "  - Replace `FIREBASE_GCS_BUCKET` with the obtained GCS bucket name. It usually has this form `YOUR_GCP_PROJECT_ID.appspot.com`.\n",
    "\n",
    "\n",
    "\n",
    "3. On the Firebase ML page, click Get started if you haven't yet enabled Firebase ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIREBASE_CREDENTIAL_PATH = 'gs://credential-csp/gcp-ml-172005-firebase-adminsdk-5gdtb-38c6644f1e.json'\n",
    "FIREBASE_GCS_BUCKET = 'gcp-ml-172005.appspot.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQVpzyftX0y0"
   },
   "source": [
    "## Create training modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AR5pU65m6nAE"
   },
   "outputs": [],
   "source": [
    "_trainer_densenet_module_file = 'flower_densenet_trainer.py'\n",
    "_trainer_mobilenet_module_file = 'flower_mobilenet_trainer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XqwYrR1GYLvm",
    "outputId": "4f8c480a-a4cd-42cc-9d5c-8d5ae822ae22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flower_densenet_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_trainer_densenet_module_file}\n",
    "\n",
    "from typing import List\n",
    "from absl import logging\n",
    "from tensorflow import keras\n",
    "from tfx import v1 as tfx\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "_IMAGE_FEATURES = {\n",
    "    \"image\": tf.io.FixedLenFeature([], tf.string),  \n",
    "    \"class\": tf.io.FixedLenFeature([], tf.int64), \n",
    "    \"one_hot_class\": tf.io.VarLenFeature(tf.float32),\n",
    "}\n",
    "\n",
    "_CONCRETE_INPUT = \"numpy_inputs\"\n",
    "_INPUT_SHAPE = (224, 224, 3)\n",
    "_TRAIN_BATCH_SIZE = 64\n",
    "_EVAL_BATCH_SIZE = 64\n",
    "_EPOCHS = 2\n",
    "\n",
    "\n",
    "def _parse_fn(example):\n",
    "    example = tf.io.parse_single_example(example, _IMAGE_FEATURES)\n",
    "    image = tf.image.decode_jpeg(example[\"image\"], channels=3)\n",
    "    class_label = tf.cast(example[\"class\"], tf.int32)\n",
    "    return image, class_label\n",
    "\n",
    "\n",
    "def _input_fn(file_pattern: List[str], batch_size: int) -> tf.data.Dataset:\n",
    "    \"\"\"Generates features and label for training.\n",
    "\n",
    "    Args:\n",
    "        file_pattern: List of paths or patterns of input tfrecord files.\n",
    "        batch_size: representing the number of consecutive elements of returned\n",
    "            dataset to combine in a single batch.\n",
    "\n",
    "    Returns:\n",
    "        A dataset that contains (features, indices) tuple where features is a\n",
    "            dictionary of Tensors, and indices is a single Tensor of label indices.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Reading data from: {file_pattern}\")\n",
    "    tfrecord_filenames = tf.io.gfile.glob(file_pattern[0] + \".gz\")\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "    dataset = dataset.map(_parse_fn).batch(batch_size)\n",
    "    return dataset.repeat()\n",
    "\n",
    "\n",
    "def _make_keras_model() -> tf.keras.Model:\n",
    "    \"\"\"Creates a DenseNet121-bases model for classifying flowers data.\n",
    "\n",
    "    Returns:\n",
    "    A Keras Model.\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=_INPUT_SHAPE)\n",
    "    base_model = keras.applications.DenseNet121(\n",
    "        include_top=False, input_shape=_INPUT_SHAPE, pooling=\"avg\"\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    x = keras.applications.densenet.preprocess_input(inputs)\n",
    "    x = base_model(\n",
    "        x, training=False\n",
    "    )  # Ensures BatchNorm runs in inference model in this model\n",
    "    outputs = keras.layers.Dense(5, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    model.summary(print_fn=logging.info)\n",
    "    return model\n",
    "\n",
    "\n",
    "def _preprocess(bytes_input):\n",
    "    decoded = tf.io.decode_jpeg(bytes_input, channels=3)\n",
    "    resized = tf.image.resize(decoded, size=(224, 224))\n",
    "    return resized\n",
    "\n",
    "\n",
    "@tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "def preprocess_fn(bytes_inputs):\n",
    "    decoded_images = tf.map_fn(\n",
    "        _preprocess, bytes_inputs, dtype=tf.float32, back_prop=False\n",
    "    )\n",
    "    return {\n",
    "        _CONCRETE_INPUT: decoded_images\n",
    "    } \n",
    "\n",
    "\n",
    "def _model_exporter(model: tf.keras.Model):\n",
    "    m_call = tf.function(model.call).get_concrete_function(\n",
    "        [tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32, name=_CONCRETE_INPUT)]\n",
    "    )\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec([None], tf.string)])\n",
    "    def serving_fn(bytes_inputs):\n",
    "        # This function comes from the Computer Vision book from O'Reilly.\n",
    "        labels = tf.constant([\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"],\n",
    "                            dtype=tf.string)\n",
    "        images = preprocess_fn(bytes_inputs)\n",
    "        \n",
    "        probs = m_call(**images)\n",
    "        indices = tf.argmax(probs, axis=1)\n",
    "        pred_source = tf.gather(params=labels, indices=indices)\n",
    "        pred_confidence = tf.reduce_max(probs, axis=1)\n",
    "        return {'label': pred_source,\n",
    "                'confidence': pred_confidence}\n",
    "\n",
    "    return serving_fn\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "    \"\"\"Train the model based on given args.\n",
    "\n",
    "    Args:\n",
    "        fn_args: Holds args used to train the model as name/value pairs.\n",
    "    \"\"\"\n",
    "    train_dataset = _input_fn(fn_args.train_files, batch_size=_TRAIN_BATCH_SIZE)\n",
    "    eval_dataset = _input_fn(fn_args.eval_files, batch_size=_EVAL_BATCH_SIZE)\n",
    "\n",
    "    model = _make_keras_model()\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=fn_args.train_steps,\n",
    "        validation_data=eval_dataset,\n",
    "        validation_steps=fn_args.eval_steps,\n",
    "        epochs=_EPOCHS,\n",
    "    )\n",
    "    _, acc = model.evaluate(eval_dataset, steps=fn_args.eval_steps)\n",
    "    logging.info(f\"Validation accuracy: {round(acc * 100, 2)}%\")\n",
    "    # The result of the training should be saved in `fn_args.serving_model_dir`\n",
    "    # directory.\n",
    "    tf.saved_model.save(\n",
    "        model, fn_args.serving_model_dir, signatures={\"serving_default\": _model_exporter(model)}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIFDOw5cmqd1",
    "outputId": "c26a9017-b14f-4f1a-ce5a-4ef98ba96270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting flower_mobilenet_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_trainer_mobilenet_module_file}\n",
    "\n",
    "from typing import List\n",
    "from absl import logging\n",
    "from tensorflow import keras\n",
    "from tfx import v1 as tfx\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "_IMAGE_FEATURES = {\n",
    "    \"image\": tf.io.FixedLenFeature([], tf.string),  \n",
    "    \"class\": tf.io.FixedLenFeature([], tf.int64),  \n",
    "    \"one_hot_class\": tf.io.VarLenFeature(tf.float32),\n",
    "}\n",
    "\n",
    "_INPUT_SHAPE = (224, 224, 3)\n",
    "_TRAIN_BATCH_SIZE = 64\n",
    "_EVAL_BATCH_SIZE = 64\n",
    "_EPOCHS = 2\n",
    "\n",
    "\n",
    "def _parse_fn(example):\n",
    "    example = tf.io.parse_single_example(example, _IMAGE_FEATURES)\n",
    "    image = tf.image.decode_jpeg(example[\"image\"], channels=3)\n",
    "    class_label = tf.cast(example[\"class\"], tf.int32)\n",
    "    return image, class_label\n",
    "\n",
    "\n",
    "def _input_fn(file_pattern: List[str], batch_size: int) -> tf.data.Dataset:\n",
    "    \"\"\"Generates features and label for training.\n",
    "\n",
    "    Args:\n",
    "        file_pattern: List of paths or patterns of input tfrecord files.\n",
    "        batch_size: representing the number of consecutive elements of returned\n",
    "            dataset to combine in a single batch.\n",
    "\n",
    "    Returns:\n",
    "        A dataset that contains (features, indices) tuple where features is a\n",
    "            dictionary of Tensors, and indices is a single Tensor of label indices.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Reading data from: {file_pattern}\")\n",
    "    tfrecord_filenames = tf.io.gfile.glob(file_pattern[0] + \".gz\")\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "    dataset = dataset.map(_parse_fn).batch(batch_size)\n",
    "    return dataset.repeat()\n",
    "\n",
    "\n",
    "def _make_keras_model() -> tf.keras.Model:\n",
    "    \"\"\"Creates a MobileNetV3-bases model for classifying flowers data.\n",
    "\n",
    "    Returns:\n",
    "    A Keras Model.\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=_INPUT_SHAPE)\n",
    "    base_model = keras.applications.MobileNetV3Small(\n",
    "        include_top=False, input_shape=_INPUT_SHAPE, pooling=\"avg\"\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    x = keras.applications.mobilenet_v3.preprocess_input(inputs)\n",
    "    x = base_model(\n",
    "        x, training=False\n",
    "    )  # Ensures BatchNorm runs in inference model in this model\n",
    "    outputs = keras.layers.Dense(5, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    model.summary(print_fn=logging.info)\n",
    "    return model\n",
    "\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "    \"\"\"Train the model based on given args.\n",
    "\n",
    "    Args:\n",
    "        fn_args: Holds args used to train the model as name/value pairs.\n",
    "    \"\"\"\n",
    "    train_dataset = _input_fn(fn_args.train_files, batch_size=_TRAIN_BATCH_SIZE)\n",
    "    eval_dataset = _input_fn(fn_args.eval_files, batch_size=_EVAL_BATCH_SIZE)\n",
    "\n",
    "    model = _make_keras_model()\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=fn_args.train_steps,\n",
    "        validation_data=eval_dataset,\n",
    "        validation_steps=fn_args.eval_steps,\n",
    "        epochs=_EPOCHS,\n",
    "    )\n",
    "    _, acc = model.evaluate(eval_dataset, steps=fn_args.eval_steps)\n",
    "    logging.info(f\"Validation accuracy: {round(acc * 100, 2)}%\")\n",
    "\n",
    "    # Convert the model.\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model.\n",
    "    # The result of the training should be saved in `fn_args.serving_model_dir` directory.    \n",
    "    with tf.io.gfile.GFile(fn_args.serving_model_dir + '/model.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gp7RTxpMoLe9",
    "outputId": "1233ba34-5b4a-4a85-8386-122c6e9b84f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://firebase_publisher.py [Content-Type=text/x-python]...\n",
      "Copying file://flower_densenet_trainer.py [Content-Type=text/x-python]...       \n",
      "Copying file://flower_mobilenet_trainer.py [Content-Type=text/x-python]...      \n",
      "Copying file://vertex_deployer.py [Content-Type=text/x-python]...               \n",
      "/ [4 files][ 12.5 KiB/ 12.5 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://vertex_uploader.py [Content-Type=text/x-python]...\n",
      "/ [5 files][ 13.8 KiB/ 13.8 KiB]                                                \n",
      "Operation completed over 5 objects/13.8 KiB.                                     \n",
      "  3.16 KiB  2021-08-05T16:02:35Z  gs://demo-experiments-gde-csp/pipeline_module/two-way-vertex-pipelines5/firebase_publisher.py\n",
      "  4.53 KiB  2021-08-05T16:02:35Z  gs://demo-experiments-gde-csp/pipeline_module/two-way-vertex-pipelines5/flower_densenet_trainer.py\n",
      "  3.37 KiB  2021-08-05T16:02:35Z  gs://demo-experiments-gde-csp/pipeline_module/two-way-vertex-pipelines5/flower_mobilenet_trainer.py\n",
      "  1.49 KiB  2021-08-05T16:02:35Z  gs://demo-experiments-gde-csp/pipeline_module/two-way-vertex-pipelines5/vertex_deployer.py\n",
      "  1.31 KiB  2021-08-05T16:02:35Z  gs://demo-experiments-gde-csp/pipeline_module/two-way-vertex-pipelines5/vertex_uploader.py\n",
      "TOTAL: 5 objects, 14181 bytes (13.85 KiB)\n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r *.py {MODULE_ROOT}/\n",
    "!gsutil ls -lh {MODULE_ROOT}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qX4M-C6X4LF"
   },
   "source": [
    "## Create the pipeline\n",
    "\n",
    "To create the end-to-end pipeline, we will need to write two custom TFX components:\n",
    "\n",
    "* One will take the pushed model from `Pusher` and will upload it to Vertex AI. \n",
    "* One will deploy the uploaded model to an Endpoint.\n",
    "\n",
    "We will then need to build a Docker image using these custom components and serve the pipeline using this image. We will use [Cloud Build](https://cloud.google.com/build) in order to build the Docker image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "SYaypU11e-cG"
   },
   "outputs": [],
   "source": [
    "_vertex_uploader_module_file = 'vertex_uploader.py'\n",
    "_vertex_deployer_module_file = 'vertex_deployer.py'\n",
    "_firebase_publisher_module_file = 'firebase_publisher.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pBj_WnLw6oRR",
    "outputId": "83adae19-5209-4032-bf94-42f1d668e947"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vertex_uploader.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_vertex_uploader_module_file}\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tfx.dsl.component.experimental.decorators import component\n",
    "from tfx.dsl.component.experimental.annotations import Parameter\n",
    "from tfx.types.standard_artifacts import String\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from tfx import v1 as tfx\n",
    "from absl import logging\n",
    "\n",
    "\n",
    "@component\n",
    "def VertexUploader(\n",
    "    project: Parameter[str],\n",
    "    region: Parameter[str],\n",
    "    model_display_name: Parameter[str],\n",
    "    pushed_model_location: Parameter[str],\n",
    "    serving_image_uri: Parameter[str],\n",
    "    uploaded_model: tfx.dsl.components.OutputArtifact[String]\n",
    "):\n",
    "\n",
    "    vertex_ai.init(project=project, location=region)\n",
    "\n",
    "    pushed_model_dir = os.path.join(\n",
    "        pushed_model_location, tf.io.gfile.listdir(pushed_model_location)[-1]\n",
    "    )\n",
    "\n",
    "    logging.info(f\"Model registry location: {pushed_model_dir}\")\n",
    "\n",
    "    vertex_model = vertex_ai.Model.upload(\n",
    "        display_name=model_display_name,\n",
    "        artifact_uri=pushed_model_dir,\n",
    "        serving_container_image_uri=serving_image_uri,\n",
    "        parameters_schema_uri=None,\n",
    "        instance_schema_uri=None,\n",
    "        explanation_metadata=None,\n",
    "        explanation_parameters=None,\n",
    "    )\n",
    "\n",
    "    uploaded_model.set_string_custom_property(\"model_resource_name\", str(vertex_model.resource_name))\n",
    "    logging.info(f\"Model resource: {str(vertex_model.resource_name)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awNiJiZ1fZsp",
    "outputId": "dd732111-6210-47ef-ef63-32bd907749dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vertex_deployer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_vertex_deployer_module_file}\n",
    "\n",
    "from tfx.dsl.component.experimental.decorators import component\n",
    "from tfx.dsl.component.experimental.annotations import Parameter\n",
    "from tfx.types.standard_artifacts import String\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from tfx import v1 as tfx\n",
    "from absl import logging\n",
    "\n",
    "\n",
    "@component\n",
    "def VertexDeployer(\n",
    "    project: Parameter[str],\n",
    "    region: Parameter[str],\n",
    "    model_display_name: Parameter[str],\n",
    "    deployed_model_display_name: Parameter[str]\n",
    "):  \n",
    "\n",
    "    logging.info(f\"Endpoint display: {deployed_model_display_name}\")\n",
    "    vertex_ai.init(project=project, location=region)\n",
    "\n",
    "    endpoints = vertex_ai.Endpoint.list(\n",
    "        filter=f'display_name={deployed_model_display_name}', \n",
    "        order_by=\"update_time\")\n",
    "    \n",
    "    if len(endpoints) > 0:\n",
    "        logging.info(f\"Endpoint {deployed_model_display_name} already exists.\")\n",
    "        endpoint = endpoints[-1]\n",
    "    else:\n",
    "        endpoint = vertex_ai.Endpoint.create(deployed_model_display_name)\n",
    "\n",
    "    model = vertex_ai.Model.list(\n",
    "        filter=f'display_name={model_display_name}',\n",
    "        order_by=\"update_time\"\n",
    "    )[-1]\n",
    "\n",
    "    endpoint = vertex_ai.Endpoint.list(\n",
    "        filter=f'display_name={deployed_model_display_name}',\n",
    "        order_by=\"update_time\"\n",
    "    )[-1]\n",
    "\n",
    "    deployed_model = endpoint.deploy(\n",
    "        model=model,\n",
    "        # Syntax from here: https://git.io/JBQDP\n",
    "        traffic_split={\"0\": 100},\n",
    "        machine_type=\"n1-standard-4\",\n",
    "        min_replica_count=1,\n",
    "        max_replica_count=1\n",
    "    )\n",
    "\n",
    "    logging.info(f\"Model deployed to: {deployed_model}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting firebase_publisher.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_firebase_publisher_module_file}\n",
    "\n",
    "from tfx import types\n",
    "from tfx.dsl.component.experimental.decorators import component\n",
    "from tfx.dsl.component.experimental.annotations import Parameter\n",
    "from tfx import v1 as tfx\n",
    "from absl import logging\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import ml\n",
    "from firebase_admin import storage\n",
    "from firebase_admin import credentials\n",
    "from google.cloud import storage as gcs_storage\n",
    "\n",
    "@component\n",
    "def FirebasePublisher(\n",
    "    pushed_model: tfx.dsl.components.InputArtifact[tfx.types.standard_artifacts.PushedModel],\n",
    "    credential_uri: Parameter[str],\n",
    "    firebase_dest_gcs_bucket: Parameter[str],\n",
    "    model_display_name: Parameter[str],\n",
    "    model_tag: Parameter[str]\n",
    ") -> tfx.dsl.components.OutputDict(result=str):\n",
    "    assert model_uri.split(\"://\")[0] == \"gs\"\n",
    "    assert credential_uri.split(\"://\")[0] == \"gs\"\n",
    "    \n",
    "    # create gcs client instance\n",
    "    gcs_client = gcs_storage.Client()\n",
    "    \n",
    "    # get credential for firebase\n",
    "    credential_gcs_bucket = credential_uri.split(\"//\")[1].split('/')[0]\n",
    "    credential_blob_path = '/'.join(credential_uri.split(\"//\")[1].split('/')[1:])\n",
    "    \n",
    "    bucket = gcs_client.bucket(credential_gcs_bucket)\n",
    "    blob = bucket.blob(credential_blob_path)\n",
    "    blob.download_to_filename('credential.json')\n",
    "    logging.info(f\"download credential.json from {credential_uri} is completed\")    \n",
    "    \n",
    "    # get tflite model file\n",
    "    model_uri = f'{pushed_model.uri}/model.tflite'    \n",
    "    tflite_gcs_bucket = model_uri.split(\"//\")[1].split('/')[0]\n",
    "    tflite_blob_path =  '/'.join(model_uri.split(\"//\")[1].split('/')[1:])\n",
    "    \n",
    "    bucket = gcs_client.bucket(tflite_gcs_bucket)\n",
    "    blob = bucket.blob(tflite_blob_path)\n",
    "    blob.download_to_filename('model.tflite')    \n",
    "    logging.info(f\"download model.tflite from {model_uri} is completed\")\n",
    "    \n",
    "    firebase_admin.initialize_app(\n",
    "        credentials.Certificate(\"credential.json\"),\n",
    "        options={\n",
    "            \"storageBucket\": firebase_dest_gcs_bucket\n",
    "        })\n",
    "    logging.info(\"firebase_admin initialize app is completed\")\n",
    "    \n",
    "    model_list = ml.list_models(list_filter=f'display_name={model_display_name}')\n",
    "    # update\n",
    "    if len(model_list.models) > 0:\n",
    "        # get the first match model\n",
    "        model = model_list.models[0]\n",
    "        source = ml.TFLiteGCSModelSource.from_tflite_model_file('model.tflite')\n",
    "        model.model_format = ml.TFLiteFormat(model_source=source)  \n",
    "        \n",
    "        updated_model = ml.update_model(model)\n",
    "        ml.publish_model(updated_model.model_id)        \n",
    "\n",
    "        logging.info(\"model exists, so update it in FireBase ML\")\n",
    "        return {\n",
    "            \"result\": \"model updated\"\n",
    "        }\n",
    "    # create\n",
    "    else:    \n",
    "        # load a tflite file and upload it to Cloud Storage\n",
    "        source = ml.TFLiteGCSModelSource.from_tflite_model_file('model.tflite')\n",
    "\n",
    "        # create the model object\n",
    "        tflite_format = ml.TFLiteFormat(model_source=source)\n",
    "        model = ml.Model(\n",
    "            display_name=model_display_name,\n",
    "            tags=[model_tag],\n",
    "            model_format=tflite_format\n",
    "        )\n",
    "\n",
    "        # Add the model to your Firebase project and publish it\n",
    "        new_model = ml.create_model(model)\n",
    "        ml.publish_model(new_model.model_id)    \n",
    "\n",
    "        logging.info(\"model doesn exists, so create one in FireBase ML\")        \n",
    "        return {\n",
    "            \"result\": \"model created\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joRJYojpP8-H"
   },
   "source": [
    "Create a package called `custom_components` and copy the modules we just wrote. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "GYiXX9pOOOAX"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./custom_components\n",
    "!touch ./custom_components/__init__.py\n",
    "!cp -r {_vertex_uploader_module_file} {_vertex_deployer_module_file} {_firebase_publisher_module_file} custom_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UiLiGjR3OOAX",
    "outputId": "ec5a7f09-df8c-4151-d3c6-51c20528d0d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16K\n",
      "-rw-r--r-- 1 jupyter jupyter    0 Aug  5 14:20 __init__.py\n",
      "drwxr-xr-x 2 jupyter jupyter 4.0K Aug  5 06:50 __pycache__\n",
      "-rw-r--r-- 1 jupyter jupyter 3.2K Aug  5 14:20 firebase_publisher.py\n",
      "-rw-r--r-- 1 jupyter jupyter 1.5K Aug  5 14:20 vertex_deployer.py\n",
      "-rw-r--r-- 1 jupyter jupyter 1.4K Aug  5 14:20 vertex_uploader.py\n"
     ]
    }
   ],
   "source": [
    "!ls -lh custom_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcFpCCSbQDol"
   },
   "source": [
    "### `Dockerfile` configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9j867lPfyM8",
    "outputId": "c4858955-56ef-444f-d683-e03630c288f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI of the custom image: gcr.io/gcp-ml-172005/flowers:tfx-1-0-0\n"
     ]
    }
   ],
   "source": [
    "DATASET_DISPLAY_NAME = \"flowers\"\n",
    "VERSION = \"tfx-1-0-0\"\n",
    "TFX_IMAGE_URI = f\"gcr.io/{GOOGLE_CLOUD_PROJECT}/{DATASET_DISPLAY_NAME}:{VERSION}\"\n",
    "print(f\"URI of the custom image: {TFX_IMAGE_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3YcE0xUgOh8",
    "outputId": "abfa72c3-dfd9-4a8f-a1b6-cf8e94b36f85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM gcr.io/tfx-oss-public/tfx:1.0.0\n",
    "RUN mkdir -p custom_components\n",
    "COPY custom_components/* ./custom_components/\n",
    "RUN pip install --upgrade google-cloud-aiplatform google-cloud-storage firebase-admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEydNZrHg6_J"
   },
   "outputs": [],
   "source": [
    "!gcloud builds submit --tag $TFX_IMAGE_URI . --timeout=15m --machine-type=e2-highcpu-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sEbNM9CeERX2"
   },
   "outputs": [],
   "source": [
    "# Specify training worker configurations. To minimize costs we can even specify two\n",
    "# different configurations: a beefier machine for the Endpoint model and slightly less\n",
    "# powerful machine for the mobile model.\n",
    "TRAINING_JOB_SPEC = {\n",
    "    'project': GOOGLE_CLOUD_PROJECT,\n",
    "    'worker_pool_specs': [{\n",
    "        'machine_spec': {\n",
    "            'machine_type': 'n1-standard-4',\n",
    "            'accelerator_type': 'NVIDIA_TESLA_K80',\n",
    "            'accelerator_count': 1\n",
    "        },\n",
    "        'replica_count': 1,\n",
    "        'container_spec': {\n",
    "            'image_uri': 'gcr.io/tfx-oss-public/tfx:{}'.format(tfx.__version__),\n",
    "        },\n",
    "    }],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "MzZdpUjypcsT"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ln1cvbcfphA9"
   },
   "outputs": [],
   "source": [
    "from custom_components.vertex_uploader import VertexUploader\n",
    "from custom_components.vertex_deployer import VertexDeployer\n",
    "from custom_components.firebase_publisher import FirebasePublisher\n",
    "\n",
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     densenet_module_file: str, mobilenet_module_file: str,\n",
    "                     serving_model_dir: str, firebase_crediential_path: str, firebase_gcs_bucket: str,\n",
    "                     project_id: str, region: str) -> tfx.dsl.Pipeline:\n",
    "    \"\"\"Creates a three component flowers pipeline with TFX.\"\"\"\n",
    "    # Brings data into the pipeline.\n",
    "    # input_base: gs://flowers-public/tfrecords-jpeg-224x224\n",
    "    example_gen = tfx.components.ImportExampleGen(input_base=data_root)\n",
    "\n",
    "    # Uses user-provided Python function that trains a model.\n",
    "    densenet_trainer = tfx.extensions.google_cloud_ai_platform.Trainer(\n",
    "        module_file=densenet_module_file,\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        train_args=tfx.proto.TrainArgs(num_steps=52),\n",
    "        eval_args=tfx.proto.EvalArgs(num_steps=5),\n",
    "        custom_config={\n",
    "            tfx.extensions.google_cloud_ai_platform.ENABLE_UCAIP_KEY:\n",
    "                True,\n",
    "            tfx.extensions.google_cloud_ai_platform.UCAIP_REGION_KEY:\n",
    "                region,\n",
    "            tfx.extensions.google_cloud_ai_platform.TRAINING_ARGS_KEY:\n",
    "                TRAINING_JOB_SPEC,\n",
    "            'use_gpu':\n",
    "                True,\n",
    "        }\n",
    "    ).with_id(\"densenet_trainer\")\n",
    "\n",
    "    # Pushes the model to a filesystem destination.\n",
    "    pushed_model_location = os.path.join(serving_model_dir, \"densenet\")\n",
    "    densnet_pusher = tfx.components.Pusher(\n",
    "        model=densenet_trainer.outputs['model'],\n",
    "        push_destination=tfx.proto.PushDestination(\n",
    "            filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "                base_directory=pushed_model_location))).with_id(\"densnet_pusher\")\n",
    "    \n",
    "    # Vertex AI upload.\n",
    "    model_display_name = \"densenet_flowers_latest\"\n",
    "    uploader = VertexUploader(\n",
    "        project=project_id,\n",
    "        region=region,\n",
    "        model_display_name=model_display_name,\n",
    "        pushed_model_location=pushed_model_location,\n",
    "        serving_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-5:latest\" \n",
    "    ).with_id(\"vertex_uploader\")\n",
    "    uploader.add_upstream_node(densnet_pusher)\n",
    "\n",
    "    # Create an endpoint.\n",
    "    deployer = VertexDeployer(\n",
    "        project=project_id,\n",
    "        region=region,\n",
    "        model_display_name=model_display_name,\n",
    "        deployed_model_display_name=model_display_name + \"_\" + TIMESTAMP\n",
    "    ).with_id(\"vertex_deployer\")\n",
    "    deployer.add_upstream_node(uploader)\n",
    "\n",
    "    # Same for the MobileNet-based model. But it will be later pushed\n",
    "    # to Firebase since it offers better features for TFLite. For now, we'll\n",
    "    # be pushing the model to a GCS location.\n",
    "    mobilenet_trainer = tfx.extensions.google_cloud_ai_platform.Trainer(\n",
    "        module_file=mobilenet_module_file,\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        train_args=tfx.proto.TrainArgs(num_steps=52),\n",
    "        eval_args=tfx.proto.EvalArgs(num_steps=5),\n",
    "        custom_config={\n",
    "            tfx.extensions.google_cloud_ai_platform.ENABLE_UCAIP_KEY:\n",
    "                True,\n",
    "            tfx.extensions.google_cloud_ai_platform.UCAIP_REGION_KEY:\n",
    "                region,\n",
    "            tfx.extensions.google_cloud_ai_platform.TRAINING_ARGS_KEY:\n",
    "                TRAINING_JOB_SPEC,\n",
    "            'use_gpu':\n",
    "                True,\n",
    "        }\n",
    "    ).with_id(\"mobilenet_trainer\")\n",
    "\n",
    "    pushed_location_mobilenet = os.path.join(serving_model_dir, \"mobilenet\")\n",
    "    mobilenet_pusher = tfx.components.Pusher(\n",
    "        model=mobilenet_trainer.outputs['model'],\n",
    "        push_destination=tfx.proto.PushDestination(\n",
    "            filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "                base_directory=pushed_location_mobilenet))).with_id(\"mobilenet_pusher\")\n",
    "\n",
    "    firebase_publisher = FirebasePublisher(\n",
    "        pushed_model=mobilenet_pusher.outputs['pushed_model'],\n",
    "        credential_uri=firebase_crediential_path,\n",
    "        firebase_dest_gcs_bucket=firebase_gcs_bucket,\n",
    "        model_display_name=model_display_name,\n",
    "        model_tag='mobilenet'\n",
    "    ).with_id(\"firebase_publisher\")    \n",
    "    \n",
    "    # Following components will be included in the pipeline.\n",
    "    components = [\n",
    "        example_gen,\n",
    "        densenet_trainer, densnet_pusher, uploader, deployer,\n",
    "        mobilenet_trainer, mobilenet_pusher, firebase_publisher\n",
    "    ]\n",
    "\n",
    "    return tfx.dsl.Pipeline(\n",
    "        pipeline_name=pipeline_name,\n",
    "        pipeline_root=pipeline_root,\n",
    "        components=components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFdlslfOX54z"
   },
   "source": [
    "## Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-AY5Z2tbsbwE"
   },
   "outputs": [],
   "source": [
    "PIPELINE_DEFINITION_FILE = PIPELINE_NAME + '_pipeline.json'\n",
    "\n",
    "# Important: We need to pass the custom Docker image URI to the\n",
    "# `KubeflowV2DagRunnerConfig` to take effect.\n",
    "runner = tfx.orchestration.experimental.KubeflowV2DagRunner(\n",
    "    config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(default_image=TFX_IMAGE_URI),\n",
    "    output_filename=PIPELINE_DEFINITION_FILE)\n",
    "\n",
    "_ = runner.run(\n",
    "    _create_pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        data_root=DATA_ROOT,\n",
    "        densenet_module_file=os.path.join(MODULE_ROOT, _trainer_densenet_module_file),\n",
    "        mobilenet_module_file=os.path.join(MODULE_ROOT, _trainer_mobilenet_module_file),\n",
    "        serving_model_dir=SERVING_MODEL_DIR,\n",
    "        firebase_crediential_path=FIREBASE_CREDENTIAL_PATH,\n",
    "        firebase_gcs_bucket=FIREBASE_GCS_BUCKET, \n",
    "        project_id=GOOGLE_CLOUD_PROJECT,\n",
    "        region=GOOGLE_CLOUD_REGION\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocHBJaR_X7x2"
   },
   "source": [
    "## Submit the pipeline for execution to Vertex AI\n",
    "\n",
    "Generally, it's a good idea to first do a local run of the end-to-end pipeline before submitting it an online orchestrator. We can use `tfx.orchestration.LocalDagRunner()` for that but for the purposes of this notebook we won't be doing that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "3elrtDOus83z",
    "outputId": "7eb13f73-602c-44f0-8385-ac8c097905ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/two-way-vertex-pipelines5-20210805160321?project=gcp-ml-172005\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from kfp.v2.google import client\n",
    "\n",
    "pipelines_client = client.AIPlatformClient(\n",
    "    project_id=GOOGLE_CLOUD_PROJECT,\n",
    "    region=GOOGLE_CLOUD_REGION,\n",
    ")\n",
    "\n",
    "_ = pipelines_client.create_run_from_job_spec(PIPELINE_DEFINITION_FILE, enable_caching=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YX3pFWlhN_jR"
   },
   "source": [
    "The pipeline should come out as the following:\n",
    "\n",
    "![](https://i.ibb.co/98Ry74n/Screen-Shot-2021-08-06-at-1-43-35-AM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-757SqrYhf3"
   },
   "source": [
    "## Making predictions with the Endpoint\n",
    "\n",
    "Some code is used from [here](https://github.com/GoogleCloudPlatform/ai-platform-samples/blob/master/ai-platform-unified/notebooks/unofficial/gapic/custom/showcase_custom_image_classification_online.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bclxNBlJ-LNu"
   },
   "source": [
    "### Imports and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6XWcRgv98gGr"
   },
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform import gapic as aip\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.json_format import MessageToJson, ParseDict\n",
    "from google.protobuf.struct_pb2 import Struct, Value\n",
    "\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zSAVSxSC9EOC"
   },
   "outputs": [],
   "source": [
    "vertex_ai.init(project=GOOGLE_CLOUD_PROJECT, location=GOOGLE_CLOUD_REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpZWBSs6-Nfz"
   },
   "source": [
    "### Programatically retrieve the latest Endpoint macthing a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ZXKmceKG8qYW",
    "outputId": "2c65421c-0211-43a2-fa12-cd69dc31cea4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3904532915999997952'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_display_name = \"densenet_flowers_latest\"\n",
    "deployed_model_display_name = model_display_name + \"_\" + TIMESTAMP\n",
    "\n",
    "endpoint = vertex_ai.Endpoint.list(\n",
    "    filter=f'display_name={deployed_model_display_name}',\n",
    "    order_by=\"update_time\"\n",
    ")[-1]\n",
    "\n",
    "endpoint_id = endpoint.name\n",
    "endpoint_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS9x3SNu-R5l"
   },
   "source": [
    "### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJeyhzeL8-2C",
    "outputId": "ace8e9b8-976b-4de4-e55b-728ff7012730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://m.economictimes.com/thumb/msid-71307470,width-1201,height-900,resizemode-4,imgsize-1040796/roses.jpg\n",
      "229376/221658 [===============================]- ETA:  - ETA:  - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "image_path = tf.keras.utils.get_file(\"image.jpg\", \n",
    "                                            \"https://m.economictimes.com/thumb/msid-71307470,width-1201,height-900,resizemode-4,imgsize-1040796/roses.jpg\")\n",
    "bytes = tf.io.read_file(image_path)\n",
    "b64str = base64.b64encode(bytes.numpy()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jmhj5-FU-TmQ"
   },
   "source": [
    "### Investigating the input key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2H6M-Usq9cUr",
    "outputId": "e5412f05-51c9-4bb6-c8b7-07b550784a74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving function input: bytes_inputs\n"
     ]
    }
   ],
   "source": [
    "pushed_model_location = os.path.join(SERVING_MODEL_DIR, \"densenet\")\n",
    "model_path_to_deploy = os.path.join(\n",
    "    pushed_model_location, tf.io.gfile.listdir(pushed_model_location)[-1]\n",
    ")\n",
    "\n",
    "loaded = tf.saved_model.load(model_path_to_deploy)\n",
    "serving_input = list(\n",
    "    loaded.signatures[\"serving_default\"].structured_input_signature[1].keys()\n",
    ")[0]\n",
    "print(\"Serving function input:\", serving_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8gnuJf1-YkC"
   },
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcB7HZat9QGI",
    "outputId": "ceafc8e4-e93f-4607-c39c-160f8356520d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(predictions=[{'confidence': 0.669201732, 'label': 'roses'}], deployed_model_id='7558456345704267776', explanations=None)\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image, endpoint, parameters_dict):\n",
    "    # The format of each instance should conform to the deployed model's prediction input schema.\n",
    "    instances_list = [{serving_input: {\"b64\": image}}]\n",
    "    instances = [json_format.ParseDict(s, Value()) for s in instances_list]\n",
    "\n",
    "    endpoint = vertex_ai.Endpoint(endpoint)\n",
    "    print(endpoint.predict(instances=instances))\n",
    "\n",
    "predict_image(b64str, endpoint_id, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Custom_Model_TFX",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-4.mnightly-2021-02-02-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:mnightly-2021-02-02-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
